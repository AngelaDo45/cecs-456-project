{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "from skimage import io, transform\n",
    "from PIL import Image as im\n",
    "import cv2\n",
    "\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not using this! \n",
    "def load_images(folder):\n",
    "    images = [] \n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "#         print(filename)\n",
    "        image = io.imread(os.path.join(folder, filename))\n",
    "        if image is not None:\n",
    "            if filename[-5] == 'R':\n",
    "                images.append(image)\n",
    "#                 images.append(image)\n",
    "                labels.append(filename[-6])\n",
    "            # display_image(image)\n",
    "    images =  np.asarray(images)\n",
    "    labels = np.asarray(labels)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images using cv2. This will give us the right dimenstion (5, 32, 32, 3)\n",
    "def load(folder):\n",
    "    images = [] \n",
    "    labels = [] \n",
    "    for filename in os.listdir(folder):\n",
    "        image = cv2.imread(os.path.join(folder, filename))\n",
    "        if image is not None:\n",
    "            if filename[-5] == 'L':\n",
    "                image = cv2.resize(image, (32,32))\n",
    "                images.append(image)\n",
    "                labels.append(filename[-6])\n",
    "    images =  np.asarray(images)\n",
    "    labels = np.asarray(labels)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img) \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = load_images('./try/')\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training dataset:  (9000, 32, 32, 3)\n",
      "Y training dataset:  (9000,)\n",
      "X testing dataset:  (1800, 32, 32, 3)\n",
      "Y testing dataset:  (1800,)\n"
     ]
    }
   ],
   "source": [
    "# obtain the training and testing dataset from the data folder\n",
    "X_train, Y_train = load('./data/train/')\n",
    "X_test, Y_test = load('./data/test/')\n",
    "\n",
    "print(\"X training dataset: \", X_train.shape)\n",
    "print(\"Y training dataset: \", Y_train.shape)\n",
    "print(\"X testing dataset: \", X_test.shape)\n",
    "print(\"Y testing dataset: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[444].shape\n",
    "X_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[444])\n",
    "plt.imshow(X_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model_1 using hw5\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(32))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005, decay=1e-6)\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=7,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_1.evaluate(X_test, Y_test)### double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_1.predict(X_test)   ### double check, not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(Y_test, axis=1)     \n",
    "y_pred = np.argmax(prediction, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence level\n",
    "# model_1.predict(X_train[0:1], batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "# check what class it is? \n",
    "# Y_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with just one image. \n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('test_image.png', target_size = (32,32))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = test_image/255\n",
    "display_image(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model_1.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## confidence level for each of the classes. highest confidence = largest value\n",
    "# np.around(result, decimals=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2nd CNN architecture using VGG-16 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              28672     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 24582     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              7000      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 6006      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 14,465,562\n",
      "Trainable params: 14,462,618\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = Sequential()\n",
    "\n",
    "vgg_model.add(Conv2D(64, (5, 5), strides = (1,1), padding='same', input_shape=X_train.shape[1:]))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Conv2D(64, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# vgg_model.add(Dropout(0.25))  # No need to use dropout when using batch normalization \n",
    "vgg_model.add(BatchNormalization())\n",
    "\n",
    "vgg_model.add(Conv2D(128, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Conv2D(128, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# vgg_model.add(Dropout(0.25))\n",
    "vgg_model.add(BatchNormalization())\n",
    "\n",
    "vgg_model.add(Conv2D(256, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Conv2D(256, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# vgg_model.add(Dropout(0.25))\n",
    "vgg_model.add(BatchNormalization())\n",
    "\n",
    "vgg_model.add(Conv2D(512, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Conv2D(512, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Conv2D(512, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# vgg_model.add(Dropout(0.25))\n",
    "vgg_model.add(BatchNormalization())\n",
    "\n",
    "vgg_model.add(Conv2D(512, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Conv2D(512, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Conv2D(512, (3, 3), strides = (1,1), padding='same'))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # vgg_model.add(Dropout(0.5))\n",
    "vgg_model.add(BatchNormalization())\n",
    "\n",
    "vgg_model.add(Flatten())\n",
    "vgg_model.add(Dense(512))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Dropout(0.5))\n",
    "vgg_model.add(Dense(num_classes))\n",
    "\n",
    "vgg_model.add(Dense(4096))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Dropout(0.5))\n",
    "vgg_model.add(Dense(num_classes))\n",
    "\n",
    "vgg_model.add(Dense(1000))\n",
    "vgg_model.add(Activation('relu'))\n",
    "vgg_model.add(Dropout(0.5))\n",
    "vgg_model.add(Dense(num_classes))\n",
    "\n",
    "vgg_model.add(Activation('softmax'))\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "282/282 [==============================] - 148s 519ms/step - loss: 1.0088 - accuracy: 0.5508 - val_loss: 5.5845 - val_accuracy: 0.1667\n",
      "Epoch 2/2\n",
      "282/282 [==============================] - 142s 504ms/step - loss: 0.3355 - accuracy: 0.8898 - val_loss: 0.3902 - val_accuracy: 0.8211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x212e4c5a910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005, decay=1e-6)\n",
    "\n",
    "vgg_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "vgg_model.fit(X_train, Y_train,\n",
    "              batch_size=32,\n",
    "              epochs=2,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "References \n",
    " - https://github.com/evernext10/Hand-Gesture-Recognition-Machine-Learning\n",
    " - https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
